https://blog.csdn.net/qq_24990189/article/details/89516490

## Grid Block Thread说明
- 线程格（grid), 线程块（block）和线程（thread）
- 每个核函数对应一个线程格，一个线程格中有一个或多个线程块，一个线程块中有一个或多个线程
- 四个变量
  - threadIdx 每个block中的thread序号
  - blockIdx  每个grid中的block序号
  - blockDim  每个block有多少thread
  - gridDim   每个grid有多少block
- 一维的情况
  - 线程全局id = blockIdex.x * blockDim.x + threadIdx.x
  - 核函数的线程总数 = gridDim.x * blockDim.x

kernel<<<blocks, threads>>>

## wrap
- block和thread之间还有一个叫做warp都东西，例如warp由32个thread组成，一个block可以有多个warp，而warp才是同步的单位，也就是说相同warp中的thread是同步执行，但同一个block中不同warp中的thread不一定是同步执行。
- warp是以32个为单位从0开始索引的，最后不足32会被填充，设计算法的时候尽量考虑到这个点，分组的时候尽量是32的倍数，还有很多操作优化到后面都应该以wrap为单位来考虑，才能更深层的优化

warp: GPU执行程序时的调度单位, 目前cuda的warp的大小为32, 同在一个warp的线程, 以不同数据资源执行相同的指令, 这就是所谓SIMT.
说人话就是, 这32个线程必须要干相同的事情, 如果有线程动作不一致, 就需要等待一波线程完成自己的工作, 然后再去做另外一件事情.

## 共享内存


- cuda中使用__shared__关键字，使用__syncthreads()控制线程同步。


## 函数声明

函数声明中，__global__、__device__、__host__三者区别是什么？
1） __global__修饰的函数是核函数，在设备端执行，可以从主机端调用，也可以在sm3以上的设备端调用（比如动态并行）；
2） __device__修饰的函数是设备函数，在设备端执行，只能从设备端调用；
3） __host__修饰的函数是主机函数，在主机端执行，只能从主机端调用；
4） __device__和__host__可以一起使用，来表示该函数可以同时在主机端和设备端执行；
5） nvcc编译选项中添加-dc（相当于--relocatable-device-code=true --compile）时，__global__函数可以调用其它文件中的__device__函数，否则只能调用同文件中的__device__函数。

https://zhuanlan.zhihu.com/p/412456340
https://zhuanlan.zhihu.com/p/416959273