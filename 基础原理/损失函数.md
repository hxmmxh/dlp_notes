

# Cross Entropy, CE
- 交叉熵
- 一般是用来量化两个概率分布之间差异的损失函数（多用于分类问题）
- https://zhuanlan.zhihu.com/p/54066141
- https://blog.csdn.net/rtygbwwwerr/article/details/50778098

# 语音识别评估标准
## WER
- 词错误率, Word Error Rate

## SER
- 句错误率, Sentence Error Rate

## CER
- 字错误率, Character Error Rate


# SDT, Sequence Discriminative training

- 当前比较流行的sequence training目标函数有最大互信息Maximum Mutual Information (MMI), boosted MMI(BMMI), 和最小贝叶斯风险 sMBR。
